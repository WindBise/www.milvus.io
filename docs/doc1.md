---
id: doc1
title: 向量检索技术
sidebar_label: 1. 向量检索技术
---

## 1.1 向量量是描述世界的基本数据类型

在现实世界中，对于复杂⽽而多元的事物，我们是很难使⽤用简单的数据类型进⾏行行描述的。例例如:我们很难 ⽤用⼏几个简单的数字来精确的描述⼀一张⼈人脸，因为⼈人脸由43块肌⾁肉构成，想要精确的描述⼀一张⼈人脸，通常 需要⼀一百维的向量量进⾏行行描述。所以，对于复杂的事物，我们通常会使⽤用特征向量量类型来进⾏行行表示。同 时，特征向量量的维度越⾼高，⼀一般也就能够更更精确的描述这个事物的特征。就像⼀一张⼋八百万的像素的图 ⽚片，每个像素还需要三个数值来分别RGB三种颜⾊色的强度，原始的特征向量量就是⼆二千四百万维的向量量， 此时可以完全⽆无损的表现这张图⽚片的内容;⼀一旦我们对这张图⽚片压缩，降低了了它的解析度或者颜⾊色深 度，特征向量量维度就会降低，相应的也就⽆无法百分百精确描述这张图了了。由此，我们可以知道: 特征向 量量特别是⾼高维特征向量量，就是描述这个世界的基本数据类型。⽽而AI、机器器学习、深度学习等近年年来热⻔门 的技术，其核⼼心的能⼒力力就是能够把复杂的事物，使⽤用相对原始特征要精简的多的特征向量量精确的描述出 来。我们以AI和机器器学习领域⾥里里，近年年来最热⻔门的深度学习技术为例例来说明这⼀一点。


## 机器器学习/深度学习技术与特征向量量

了了解机器器学习/深度学习的起源，⾸首先让我们先来了了解⼀一下⼈人类的⼤大脑是如何⼯工作的。⼤大脑的⼯工作过程， 是⼀一个对接收信号不不断迭代、不不断抽象概念化的过程，这个过程其实和我们的常识是相吻合的，因为复 杂的图形，往往就是由⼀一些基本结构组合⽽而成的。同时我们还可以看出:⼤大脑是⼀一个深度架构，认知过 程也是深度的。⽽而深度学习，恰恰就是通过组合低层特征形成更更加抽象的⾼高层特征(或属性类别)。因 此⼤大脑的认知过程就是不不断把复杂事物抽象成特征的过程，机器器学习/深度学习就是对这⼀一过程的模拟。
随着近年年来计算机技术的不不断进步，特别是以NVIDIA的GPU为代表的新⼀一代异构众核⾼高性能计算芯⽚片的 诞⽣生，使得深度学习技术的应⽤用得到了了⻓长⾜足的进步。但是⽆无论是⽬目前基于卷积神经⽹网络(CNN)的深度学 习系统，还是当前⽕火热的基于循环神经⽹网络(RNN)的深度学习系统，其训练出来的模型在⽤用于实际预测 的时候，都是将输⼊入的事物以⾼高维特征向量量的形式输出的。下⾯面将列列举⼀一些具体的机器器学习或者深度学 习的应⽤用场景:

- 在⼈人脸识别的领域，2018年年3⽉月来⾃自中国的DeepInsight团队的使⽤用InsightFace⼈人脸识别库的深度 学习技术，训练出来的模型，取得了了MegaFace⼈人脸识别⽐比赛的第⼀一名，其产⽣生的⼈人脸特征向量量为 512维，识别率超过98%。
- 在⾃自然语⾔言处理理领域，Google的word2vector算法可以算是基⽯石算法，其原理理就是把⾃自然语⾔言中 的字和词转化为300维的词向量量。然后再利利⽤用词向量量在向量量空间上的位置，就可以度量量出词与词的 关系。
- 在语⾳音识别领域，⽆无论是前⼏几年年最热⻔门的基于RNN/LTSM⽅方案，还是现在基于注意⼒力力模型的⽅方案， ⾸首先需要解决的就是对语⾳音提取其特征向量量，然后才能展开后续分析。

由上⾯面的这些例例⼦子，我们发现特征向量量，特别是⾼高维特征向量量在当前和未来的AI领域，都扮演着表达世 界万事万物基础数据类型的⻆角⾊色。

因此，在海海量量的特征向量量中能够精确⽽而⾼高效地进⾏行行检索，也就越来越成为AI技术⼤大规模应⽤用的必要条 件，同时也是对传统数据库系统的⼀一个挑战。

## 1.2 向量量检索技术的背景

所谓的向量量检索，本质就是向量量的相似性检索技术，也就是对于给定向量量，在欧⼏几⾥里里德距离上，找出最
接近向量量列列表的检索技术;或者通过计算点积，返回向量量点积最⾼高的向量量列列表的检索技术。这样针对向
量量的检索技术，在现实中的许多场景下具备重要价值:
- 搜索引擎需要判断搜索语句句的相似度。例例如，问答⽹网站如知乎，Quora，StackOverflow等，需要 判断并提示⽤用户想问的问题是否已有类似问题已经被提出过，本质就是利利⽤用前⽂文所说的⾃自然语⾔言处理理技术产⽣生搜索语句句的特征向量量，在已经被提问过问题的特征向量量空间⾥里里，返回相似性最⾼高的条⽬目。
- 在安防、刑侦等领域，安全部⻔门需要在众多监控拍到的照⽚片中，找到与嫌疑⼈人或嫌疑⻋车辆等最相似的照⽚片，以准确快速定位。其本质就是利利⽤用前⽂文所说的深度学习训练出的模型，产⽣生嫌疑⼈人像或嫌疑⻋车辆照⽚片的特征向量量，然后到海海量量的监控视频和图⽚片中，搜索相似度最⾼高的条⽬目。
- 在天⽓气预报领域，应⽤用机器器学习技术利利⽤用对历史天⽓气资料料信息进⾏行行训练，把历史天⽓气映射到⾼高维度矩阵空间中。当需要查询当前天⽓气的类型和后续的演变时，就可以使⽤用相同的模型，把当前天⽓气情况转换成特征向量量，通过⽐比较向量量的相似性，就能够找到历史上对应的天⽓气变化情况，从⽽而实现准确的天⽓气预报⼯工作。

向量量相似性检索的应⽤用场景数不不胜数，上述的例例⼦子只是冰⼭山⼀一⻆角。向量量相似性检索在数据科学领域，将会扮演越来越重要的⻆角⾊色。

## 1.3 传统数据库针对向量量类型的解决⽅方案
那么传统数据库系统和大数据系统，在向量相似性检索领域的表现会怎么样呢？随着机器学习或者深度学习技术越来越成熟，应用越来越广泛，随之而产生的特征向量数据也会越来越庞大。传统的数据库系统和大数据系统，由于其内建数据类型里并不包括特征向量类型。如果打算使用传统的数据库系统进行特征向量检索，要么自定义特征向量类型以及针对该类型数据的自定义函数；要么就只能按照一维一列的方式把高维向量存入数据库系统，由于大多数数据库系统对于表列数的支持都是有限的，因此使用这种方法通常无法支持高维特征向量。此外，传统的数据库和大数据系统里，除了没有针对该数据类型的存储方式、计算方法，也没有针对该类型的索引方式以及数据的管理方式，由此可见使用传统的数据库和大数据系统进行特征向量的存储和检索，都是不合适的。当然，现在一些传统数据库系统也提供了针对特征向量检索的插件：例如，PostgreSQL的以图搜图插件imgsmlr和自然语言处理的插件word2vector，但是由于传统数据库系统，本身是针对基于哈希搜索或者基于一维离散数据搜索而优化的，并没有针对高维向量搜索进行优化，所以这些插件虽然能用，但是功能也不强大，效率也很低，并不能满足海量高维向量的搜索。

OpenCV 等工具包里包含的相似性搜索功能，在扩展性上的限制非常大。其他针对“小”数据集的相似性搜索算法库也是这么个情况（比如，一百万个向量 ），且大多是学术研究的产物，为发表的论文而开发，用来在特定设定下展示效果。



## 1.4 向量检索算法的发展现状

通常来说，面向向量的相似性检索的方法分成：精确检索和近似检索两类。而精确检索的本质就是线性查找：

1.4.1 线性查找

通过在整个向量空间内，遍历所有已存向量计算其与检索向量的距离，通常是计算欧几里德距离或者点积。欧式距离最近的向量或者点积最大的向量就是相似度最高的向量。线性查找算法简单，不需要建立额外的数据结构和存储空间，通过使用例如Intel架构下的MKL或者使用NVIDIA GPU的cublas等并行计算库加速，对于中小规模的向量集的相似性检索是合适的。但是，由于线性查找的时间复杂度是O(Nd)，其中N是向量集的规模，d是向量的维度，随着向量集的规模的增大或者向量维度的增加，线性查找就会显得力不从心。

1.4.2 近似检索

所谓近似检索，就是通过聚类、降维或者编码等方式，将原来需要在全量高维向量空间内的搜索，转换为在小范围空间或者相对低维的向量空间内搜索的算法。这类算法的特点是，检索的时间复杂度小于O(Nd)，但是真正用来搜索之前，需要用一个向量分布类似的一个训练集来训练，获得一个产生合理数据划分或者编码的模型。然后再利用这个模型，使用额外的存储空间，建立对全量高维向量的索引。目前近似检索的算法，通常分为：基于树的搜索算法，基于哈希的空间划分法和向量量化的编码法。

1.4.2.1 基于树的搜索算法

基于树的搜索算法是一个以树为数据结构的近似最近邻搜索算法。其核心是不断用选取的两个质心的法平面对空间进行分割，最终将每一个区分的子空间里面的样本数据限制在K以内。对于待插入的样本Xi，从根节点依次使用法向量跟Xi做内积运算，从而判断使用法平面的哪一边（左子树or右子树）。对于查询向量Qi，采用同样的方式（在树结构上体现为从根节点向叶子节点递归遍历），即可定位到跟Qi在同一个子空间或者邻近的子空间的样本，这些样本即为Qi近邻。实际应用中还可以通过建立多棵树的方式，提高查询的准确率。

1.4.2.2 基于哈希的空间划分法

基于哈希的空间划分法是利用哈希函数对把需要搜索的特征空间，划分称为多个子空间。然后把带插入的向量根据前面的哈希函数，聚类到不同的子空间中，一般来说相同子空间内向量的空间距离相对更接近。然后把这些向量分别记录在每个子空间的倒排列表中。对于查询向量的来说，首先也是用哈希函数找到和这个向量最近的一个或多个子空间。然后再根据子空间中心点到该向量的距离，由近及远，计算其倒排列表中所有向量与查询向量的距离。最后根据距离，选出距离最近的k个向量作为返回结果。

1.4.2.3 向量量化的编码算法

向量量化方法的本质也是聚类，它的方法是这样的：在训练阶段，针对训练样本集合，会将其样本维度d进行切分。假设切分为n个子空间，每个子空间的维度就是d/n。然后再在每个子空间中，对子向量进行聚类，如此每个子空间都可以获得一个编码集。这样训练样本的每个子段，都可以用子空间聚类中心来近似，对应的编码也就是类中心的ID了。通过这样的编码方式，训练样本就可以用很短的编码进行表示，从而达到量化的目的。对于待编码的数据，使用相同的切分方案，完成所有编码。如此，在查询向量到来的时候，原先全样本的距离计算，就可以转化为子空间聚类中心的距离计算，从而大大简化了向量检索的时间。此外，由于该算法对特征向量进行编码后的信息较短，其额外的空间占用率也并不高。但是，该算法的精度与子空间划分的大小和编码长度有的关系。目前，该类算法的查询性能优秀，但是精度较其他算法要低。

除了上面提到的三类算法，近年来基于邻近图的最近邻搜索算法，在向量检索领域开始突破。邻近图算法的核心思想也是聚类，通过把距离最近的向量，用图连接的方式连接起来。这样当我们在查询的时候，就可以利用"邻居的邻居也可能是邻居"的原理，找到最相似的向量。



## 1.5 当前向量检索的实现

上面已经介绍了现在向量检索算法发展现状，下面我们来看一下工业界的一些具体实现。

1.5.1 Annoy

Annoy(Approximate Nearest Neighbors Oh Yeah) 是由Spotify使用C++实现的向量检索库，同时提供带有Python的封装。Spotify内部使用Annoy来进行音乐推荐：通过把用户的喜爱听的音乐信息向量化，从而建立了高维向量空间，使用Annoy进行向量检索，能实现快速的音乐推荐功能。Annoy的特点在于，内存占用小，虽然高维向量的搜索表现也不错，但是对于小于100维的向量，搜索效果最好。

Annoy的问题在于，搜索精度并不算高，且本身只是一个算法库。

1.5.2 FAISS

FAISS 是 Facebook AI 研究团队开源的针对聚类和相似性搜索库。FAISS 是用 C++ 编写的，带有 Python / numpy 的完整封装。FAISS大量利用了：

- 多线程以充分利用多核性能并在多路 GPU 上进行并行搜索。
- BLAS 算法库通过 matrix/matrix 乘法进行高效、精确的距离计算。没有 BLAS，高效的强力执行很难达到最优状态。 BLAS/LAPACK 是唯一一个 Faiss 必须的前提软件。
- 机器 SIMD 矢量化和 popcount 被用于加速孤立矢量的距离计算。

FAISS包含了多种向量检索算法，提供不同精度，查询速度和存储空间占用率。它还包含用于评估和参数调整的支持代码。 FAISS的出现也打破了过去向量检索库的一个限制：只能提供某个方面的优化。FAISS允许开发人员，在建立索引的速度、查询速度、内存使用量和查询精度等多个方面做取舍。

FAISS虽然有上述的种种优点，但是依然只是一个算法库；虽然提供了多种算法和参数以供调优，但是对于开发人员而言，想用好FAISS依然有很高的门槛。

1.5.3 NSG

基于图结构的超大规模高维向量数据检索技术，由阿里巴巴-浙江大学前沿技术联合研究中心的数据挖掘实验室推出的，面向高维向量数据检索算法。目前，根据大量测试证明该算法在查询速度、查询精确度以及内存占用上均有不小的优势，目前已经被淘宝集成进其搜索引擎。但是，这种基于图结构的向量搜索算法，在建立索引，也就是建立图的时候速度要显著慢于传统的向量检索算法。在需要大量插入新向量的同时进行查询的场景下，NSG算法就不适合了。

1.5.4 SPTAG

SPTAG是由Microsoft于2019年5月发布的，基于最近邻搜索的向量检索算法。开发人员称该算法：允许用户充分利用学习模型在以毫秒为单位时间内智能搜索数十亿条向量。该算法在查询速度、查询精确度以及内存占用上也都有非常好的表现。和NSG类似，SPTAG建图的过程非常漫长，所以在需要大量插入新向量的同时进行查询的场景下，SPTAG也并不合适。

综上所述，当前工业界针对向量检索的实现中，并没有一个能擅长所有场景的万能算法。同时现有的实现也都还只是算法库，而并非一个系统。随着AI应用的大规模落地，提供一个面向海量特征向量检索的数据库系统，已经是市场对于数据库厂商提出的新需求。